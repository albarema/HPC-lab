---
title: "HPC best practices"
format: 
  html:
    toc: false
authors:
  - name: Alba Refoyo Martinez 
    orcid: 0000-0002-3674-4007
  - name: Jennifer Bartell 
    orcid: 0000-0003-2750-9678
date-modified: last-modified
date-format: long
---

### <span style="color: red;">Note: Content in Progress</span>

High Performance Computing (HPC) plays a crucial role for researchers by offering the computational speed and power needed to manage large and complex data sets, perform simulations, and address intricate problems that would be impractical or too time-consuming with standard computing methods.

Knowing which HPC resources are accessible and how to use them efficiently is essential for researchers. Making the most of these resources can significantly expedite research and drive innovation. By becoming proficient with the available tools and technologies, researchers can address complex challenges, analyze extensive data sets, and execute advanced simulations with increased speed and accuracy. This module provides essential knowledge on HPC resources and best practices for their utilization.

This module offers content for three distinct courses:

- **HPC Launch**: Foundations on HPC and essential knowledge on national HPC resources
- **HPC Pipes**: Best practices for using workflow management systems and computational environments with HPC
- **HPC ML (Machine Learning)**: Insights into applying HPC for machine learning tasks, including model training, data analysis, and optimization techniques.

By the end of all the modules, you will gain practical skills in promoting reproducibility through comprehensive training in HPC resource management, workflow pipelines, and computing environments.

::: {.callout-tip title="Course Goals"}
By the end of this workshop, you should be able to apply the following concepts in the context of Next Generation Sequencing data:

- Understand the Importance of Research Data Management (RDM)
- Make your data analysis and workflows reproducible and FAIR
- Make FAIR environment using conda or Docker
:::


## HPC pipes
The course "HPC pipes" is designed to provide participants with foundational knowledge and practical skills in writing reproducible pipelines. As part of effective data management, it is crucial that researchers create reproducible analyses that enable others to validate and build upon their work. We will explore essential elements of reproducibility and efficiency in computational research, highlighting techniques and tools for creating robust and transparent coding and workflows. By prioritizing reproducibility and replicability, researchers can enhance the credibility and impact of their findings while fostering collaboration and knowledge dissemination within the scientific community. This approach guarantees efficient research management. Explore our content on [practical RDM](https://hds-sandbox.github.io/RDM_NGS_course/) for more details.

:::{.callout-warning title="HPC best practices"}
We offer in-person workshops, keep an eye on the upcoming events on the [Sandbox website](https://hds-sandbox.github.io/news.html).
:::


#### Acknowledgements
