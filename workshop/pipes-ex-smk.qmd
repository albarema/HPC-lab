---
title: Day 1 - Part 2 
format: 
  html: default
summary: intro to workflows
css: ./web.css
---

```{r, echo = FALSE, results='asis'}
library(webexercises)

knitr::opts_chunk$set(echo = FALSE)

# Uncomment to change widget colours:
style_widgets(incorrect = "red", correct = "green", highlight = "firebrick")

```

Put your learning to the test with what youâ€™ve covered so far.

## A. General knowledge

::: {.webex-check .callout-exercise}
# I - General knowledge 

```{r, results='asis', echo = FALSE}

opts_1 <- c(
   answer="Automating the execution of complex computational processes",
   "To manually execute each step of a computation",
   "Offering real-time and intuitive data analysis",
   "To minimize the reliance on specific software environments"
)

cat("**G.1. What role does a workflow manager play in computational research?**", longmcq(opts_1))
```


```{r, results='asis', echo = FALSE}

opts_2 <- c(
   answer="Limited error handling and debugging capabilities",
   "Difficulty in integrating with notebooks",
   "Not compatible with all operating systems",
   answer="They re-run all the steps every time",
   "Insufficient support for parallel processing",
   "Complex and extensive coding for simple tasks"
)

cat("**G.2.What is the primary drawback of using shell scripts for automating computations?**", longmcq(opts_2))

```

```{r, results='asis', echo = FALSE}
#| echo: false
opts_3 <- c(
   answer="Executing tasks only when required",
   answer = "Managing task dependencies",
   answer = "Overseeing storage and resource allocation",
   "Providing intuitive graphical interfaces"
)

cat("**G.3. What are the key features of workflow manager in computational research?**
(Several possible solutions)",  longmcq(opts_3))
```

**G.4. Workflow managers can run tasks (different) concurrently if there are no dependencies** (True or False) `r torf(TRUE)`

**G.5. A workflow manager can execute a single parallelized task on multiple nodes in a computing cluster** (True or False) `r torf(TRUE)`
:::

## B. Snakemake

::: {.webex-check .callout-exercise}
# II - Exploring rule invocation in Snakemake

In this exercise, we will explore how rules are invoked in a Snakemake workflow. Download the `Snakefile` and data required for this exercise using the links below if you are running things locally. 

<div style="display: flex; gap: 10px;">
  <a href="../develop/scripts/samples_1kgp_test.tsv" download="samples_1kgp_test.tsv">
    <button class="btn small-button">Download data input</button>
  </a>

  <a href="../develop/scripts/process_1kgp.smk" download="process_1kgp.smk">
    <button class="btn small-button">Download Snakefile</button>
  </a>
</div>

Alternatively, start a new job in UCloud, ensuring that you mount both your personal drive and the shared `hpclab-workshop` shared drive. The snakemake file is located at: `/work/HPCLab_workshop/rules/process_1kgp.smk`. 

:::{.callout-important}
# Why do we need to mount two drives for the exercises?

- YourNameSurname#xxxx: save your results here or any other file. 
- hpclab-workshop: this is where the input files are located; you can read from this directory but do not have write permissions. 
:::

Now follow these steps and answer the questions: 

- Open the snakefile, named `process_1kgp.smk` and try to understand every single line. **If you request Snakemake to generate the file `results/all_female.txt`, what commands will be executed and in what sequence?**
- Open a terminal and navigate to your personal drive `cd /work/YourNameSurname#xxxx`. Create a subdir called, for example, `hpclab` and make it your working directory. You can to save all results here!
- **Dry-run** the workflow: Check the number of jobs that will be executed.

   **S.1. How many jobs will Snakemake run?** `r fitb(8)`

- Run the workflow from your the directory `hpclab` you have created on your drive. Use the name flag `--snakefile <snakefile.smk> --jobs 1` | `-s <snakefile.smk> -j 1`. 
- Verify output: Ensure that the output files are in your working directory.
- Clean Up: remove all files starting with `EUR` in your results folder.
- Rerun the workflow: Execute the Snakefile again.

   **S.2. How many jobs did Snakemake run in this last execution?** `r fitb(3)`

- Remove lines 4-6 in the `process_1kgp.smk`. How else can you run the workflow but to generate instead `all_male.txt` using only the command-line? 

   ```
   rule all:
      input:
         expand("results/all_{gender}.txt", gender=["female"])
   ```
   
   **S.3. Tip: what is missing at the end of the command ( e.g. what should be added to ensure `all_male.txt` is generated)? `snakemake -s process_1kgp.smk -c1`** `r fitb("results/all_male.txt")`


:::{.callout-hint}
# Solution 
```{.bash}
# dry run 
snakemake -s process_1kgp.smk -n 
# run the workflow 
snakemake -s process_1kgp.smk-c1 <name_rule|name_output>
# verify output 
ls <name_output>
# remove file belonging to european individuals 
rm results/EUR.tsv results/all_female.txt
# rerun again 
snakemake -s process_1kgp.smk -c1 <name_rule|name_output>
```
:::

:::